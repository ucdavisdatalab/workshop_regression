[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "A Practical Introduction to Regression Modeling in R",
    "section": "",
    "text": "1 Description\nRegression modeling — using input variables to predict or model the value of a response — is widely used in pretty much every field of research. Yet many graduate programs don’t include formal training in statistical modeling, and the DataLab’s office hours indicate widespread anxiety about using regression models in practice. This workshop is intended to help address that anxiety by teaching the fundamentals of using regression modeling. The emphasis is on practice and intuition, with only a small amount of math. This workshop is open to all UC Davis graduate students and postdoctoral scholars. Attendance at both sessions is required. Instruction is in-person and seats are limited. A Zoom link (e.g., broadcast) will be available for those unable to attend who would like to watch live."
  },
  {
    "objectID": "index.html#workshop-structure",
    "href": "index.html#workshop-structure",
    "title": "A Practical Introduction to Regression Modeling in R",
    "section": "1.1 Workshop Structure",
    "text": "1.1 Workshop Structure\nThis workshop describes itself as a practical introduction. That means you are expected to get practice with regression, so please follow along! The workshop follows the examples in this document, and we will walk through each of them live, taking time to discuss the what and why of regression modeling. Your experience will be far more rewarding if you open up a fresh file in RStudio and follow along!\nThe first day of the workshop series will cover linear and generalized linear regression, including discussions of checking model assumptions and how to handle categorical vs. continuous features. The second day will focus on random effects and mixed effect modeling."
  },
  {
    "objectID": "index.html#learning-objectives",
    "href": "index.html#learning-objectives",
    "title": "A Practical Introduction to Regression Modeling in R",
    "section": "1.2 Learning objectives",
    "text": "1.2 Learning objectives\nAfter this workshop, learners will be able to: - Explain the differences between linear and generalized linear regression models - Explain the differences between fixed effects and random effects - Describe how continuous and categorical variables are handled differently by regression modeling software - Implement the above-mentioned model types - Read and interpret regression summary tables - Do diagnostic checks on regression models"
  },
  {
    "objectID": "01_introduction.html#data",
    "href": "01_introduction.html#data",
    "title": "2  Introduction",
    "section": "2.1 Data",
    "text": "2.1 Data\nThe data for a linear model are typically in a tabular format (imagine a spreadsheet), where each row of data is called an observation and each column is called a feature. The column that is the outcome of the model is called the response. Each observation should include a value for every feature (there are some ways of handling missing data but that’s beyond our scope for this workshop)."
  },
  {
    "objectID": "01_introduction.html#plot-before-you-model",
    "href": "01_introduction.html#plot-before-you-model",
    "title": "2  Introduction",
    "section": "2.2 Plot before you model!",
    "text": "2.2 Plot before you model!\nYour computer will do whatever you tell it to do, even if it’s not a good idea. With this great power comes the responsibility to think, and to check your assumptions.\nThe first one to mention is the assumption that there is a relationship between the features and the response, of the type that the model describes. Your first, best way to test that assumption is to plot the data. Summaries like the means, variances, and correlations can only tell you so much. The following example points out why.\nThe Datasaurus Dozen are a collection of thirteen data sets. Each consists of two features (x and y) that have the same means, variances, and correlations.\n\n\n# A tibble: 13 × 6\n   dataset    correlation x_mean x_variance y_mean y_variance\n   &lt;chr&gt;            &lt;dbl&gt;  &lt;dbl&gt;      &lt;dbl&gt;  &lt;dbl&gt;      &lt;dbl&gt;\n 1 away            -0.064   54.3       281.   47.8       726.\n 2 bullseye        -0.069   54.3       281.   47.8       726.\n 3 circle          -0.068   54.3       281.   47.8       725.\n 4 dino            -0.064   54.3       281.   47.8       726.\n 5 dots            -0.06    54.3       281.   47.8       725.\n 6 h_lines         -0.062   54.3       281.   47.8       726.\n 7 high_lines      -0.069   54.3       281.   47.8       726.\n 8 slant_down      -0.069   54.3       281.   47.8       726.\n 9 slant_up        -0.069   54.3       281.   47.8       726.\n10 star            -0.063   54.3       281.   47.8       725.\n11 v_lines         -0.069   54.3       281.   47.8       726.\n12 wide_lines      -0.067   54.3       281.   47.8       726.\n13 x_shape         -0.066   54.3       281.   47.8       725.\n\n\n\n\n\nYou probably wouldn’t use a linear model for most of the panels of that plot because there isn’t a linear relationship between the feature (x-direction) and the response (y-direction). Plotting the data can also reveal problems or oddities in the data that will guide your further investigation."
  },
  {
    "objectID": "02_linear_model.html#palmer-penguins-data",
    "href": "02_linear_model.html#palmer-penguins-data",
    "title": "3  Linear Regression",
    "section": "3.1 Palmer penguins data",
    "text": "3.1 Palmer penguins data\nThis first example will use data from the palmerpenguins package. It was created by Allison Horst and contains observations of 344 penguins from the Palmer Station Antarctica LTER site. There are eight features: year, species, sex, island, bill width (mm), bill length (mm), flipper length (mm), and body mass (g). We’ll begin by installing and then importing the palmerpenguins package, and then loading the data.\n\ninstall.packages(\"palmerpenguins\")\nlibrary(palmerpenguins)\ndata(penguins)\n\nThe data is loaded. Let’s look at it. First, we’ll familiarize ourselves with the values.\n\n# check out the palmer penguins data\nsummary(penguins)\n\n      species          island    bill_length_mm  bill_depth_mm  \n Adelie   :152   Biscoe   :168   Min.   :32.10   Min.   :13.10  \n Chinstrap: 68   Dream    :124   1st Qu.:39.23   1st Qu.:15.60  \n Gentoo   :124   Torgersen: 52   Median :44.45   Median :17.30  \n                                 Mean   :43.92   Mean   :17.15  \n                                 3rd Qu.:48.50   3rd Qu.:18.70  \n                                 Max.   :59.60   Max.   :21.50  \n                                 NA's   :2       NA's   :2      \n flipper_length_mm  body_mass_g       sex           year     \n Min.   :172.0     Min.   :2700   female:165   Min.   :2007  \n 1st Qu.:190.0     1st Qu.:3550   male  :168   1st Qu.:2007  \n Median :197.0     Median :4050   NA's  : 11   Median :2008  \n Mean   :200.9     Mean   :4202                Mean   :2008  \n 3rd Qu.:213.0     3rd Qu.:4750                3rd Qu.:2009  \n Max.   :231.0     Max.   :6300                Max.   :2009  \n NA's   :2         NA's   :2                                 \n\nprint(penguins)\n\n# A tibble: 344 × 8\n   species island    bill_length_mm bill_depth_mm flipper_length_mm body_mass_g\n   &lt;fct&gt;   &lt;fct&gt;              &lt;dbl&gt;         &lt;dbl&gt;             &lt;int&gt;       &lt;int&gt;\n 1 Adelie  Torgersen           39.1          18.7               181        3750\n 2 Adelie  Torgersen           39.5          17.4               186        3800\n 3 Adelie  Torgersen           40.3          18                 195        3250\n 4 Adelie  Torgersen           NA            NA                  NA          NA\n 5 Adelie  Torgersen           36.7          19.3               193        3450\n 6 Adelie  Torgersen           39.3          20.6               190        3650\n 7 Adelie  Torgersen           38.9          17.8               181        3625\n 8 Adelie  Torgersen           39.2          19.6               195        4675\n 9 Adelie  Torgersen           34.1          18.1               193        3475\n10 Adelie  Torgersen           42            20.2               190        4250\n# ℹ 334 more rows\n# ℹ 2 more variables: sex &lt;fct&gt;, year &lt;int&gt;\n\n\nSuppose we think that all penguins grow in a certain proportional way. Then we may be able to estimate the penguin’s mass based on the length of its flipper. Let’s take a look at how that relationship looks in the data.\n\n\nCode\nggplot(penguins) +\n  aes(x=flipper_length_mm, y=body_mass_g) +\n  geom_point() +\n  xlab(\"Flipper length (mm)\") +\n  ylab(\"Penguin mass (g)\") +\n  geom_smooth(method='lm', se=FALSE)\n\n\n\n\n\nI’ve added a regression line to illustrate the assumed linear relationship. Obviously, you’d want your model of the response to fit perfectly but there’s no line that would go through all the points."
  },
  {
    "objectID": "02_linear_model.html#residuals",
    "href": "02_linear_model.html#residuals",
    "title": "3  Linear Regression",
    "section": "3.2 Residuals",
    "text": "3.2 Residuals\nWe have a special term for the difference between the fitted line and the dots. We call the differences residuals, and there is one per dot. The difference is calculated as the vertical distance, as shown here:\n\n\nCode\nggplot(penguins) +\n  aes(x=flipper_length_mm, y=body_mass_g) +\n  geom_point() +\n  xlab(\"Flipper length (mm)\") +\n  ylab(\"Penguin mass (g)\") +\n  geom_smooth(method='lm', se=FALSE) +\n  geom_segment(\n    data=mutate(\n      penguins,\n      fitted = predict(m_p, penguins))[250:251,],\n    mapping=aes(x=flipper_length_mm,\n                xend=flipper_length_mm,\n                y=body_mass_g,\n                yend=fitted),\n    color='red',\n    lwd=1\n  )"
  },
  {
    "objectID": "02_linear_model.html#how-the-line-is-calculated",
    "href": "02_linear_model.html#how-the-line-is-calculated",
    "title": "3  Linear Regression",
    "section": "3.3 How the line is calculated",
    "text": "3.3 How the line is calculated\nA line is totally defined by its slope and intercept (intercept is where the line crosses the y-axis). The math of linear regression is just a way to calculate the slope and intercept of that line, and its intuition is also quite simple. It starts with the goal of minimizing the errors. There is an error for each dot, which is the difference between the line and the dot. To minimize the errors, we need to combine all those numbers into one (otherwise, you might have to worry about what effect a change in “A” has on “B”, etc.) A natural way to combine many numbers into one is to add them together. But there is a problem: errors can be negative (when the model fit is greater than the observed data.) If that seems complicated, just understand that both of these lines have residuals that sum to zero:\n\n\nCode\nlibrary(cowplot)\n\nregression_plot = ggplot(penguins) +\n  aes(x=flipper_length_mm, y=body_mass_g) +\n  geom_point() +\n  xlab(\"Flipper length (mm)\") +\n  ylab(\"Penguin mass (g)\") +\n  geom_smooth(method='lm', se=FALSE)\n\nmean_plot = ggplot(penguins) +\n  aes(x=flipper_length_mm, y=body_mass_g) +\n  geom_point() +\n  xlab(\"Flipper length (mm)\") +\n  ylab(\"Penguin mass (g)\") +\n  geom_hline(\n    mapping=aes(yintercept=mean(body_mass_g, na.rm=TRUE)),\n    color=\"blue\",\n    lwd=1)\n\ncowplot::plot_grid(regression_plot, mean_plot, ncol=2)\n\n\n\n\n\nA large negative error may be a good thing for “minimizing” error, but we don’t want that because the error is large. So the errors are squared before adding them together. This is the origin of terms you might have heard, like the sum of squared errors or the mean squared error.\n\n3.3.1 The lm() function in R\nThe function to estimate a linear regression model in R is called lm(). We’ll get quite familiar with the function during this workshop. Now let’s use it to estimate the regression line in our penguin body size example.\n\npenguin_mass_model = lm(\n  body_mass_g ~ flipper_length_mm,\n  data=penguins)\nsummary(penguin_mass_model)\n\n\nCall:\nlm(formula = body_mass_g ~ flipper_length_mm, data = penguins)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-1058.80  -259.27   -26.88   247.33  1288.69 \n\nCoefficients:\n                   Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)       -5780.831    305.815  -18.90   &lt;2e-16 ***\nflipper_length_mm    49.686      1.518   32.72   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 394.3 on 340 degrees of freedom\n  (2 observations deleted due to missingness)\nMultiple R-squared:  0.759, Adjusted R-squared:  0.7583 \nF-statistic:  1071 on 1 and 340 DF,  p-value: &lt; 2.2e-16\n\n\nThere is a bit of unique R code in the call to lm(): it uses R’s formula syntax. A formula in R has the response variable on the left of a tilde (~) and predictors on the right. You may see it in other contexts but its most common use is to specify the variables of a regression formula. Having used the lm() function to estimate the regression model, we then use the summary() function to inspect the model fit. Let’s dig into the summary() output.\nThe important parts of the summary() results are the Coefficients: and below. The first two parts of the summary() result (Call: and Residuals:) are usually not very interesting. At this point, you probably recognize that the Call: is repeating back the function call that created the model, and the Residuals: section tells you about the size of the residuals.\nStarting with Coefficients: we begin to learn about the model fit. You remember that the linear model fits a straight line to the data. And you might also know that you can describe a line by its slope and intercept, as in \\(y = mx + b\\). In that equation, \\(b\\) is the intercept and \\(m\\) is the slope, also known as the coefficient of \\(x\\). The coefficient of flipper_length_mm functions as the slope of our line, and it is listed in the Estimate column. As you might guess, the intercept of the estimated line is listed as under the Estimate column and the (Intercept) row.\nThe Std. Error column is an estimate of uncertainty in the coefficient estimates. The t value column is just the Estimate divided by the Std. Error, and it is used to calculate the Pr(&gt;|t|) column (better known as the coefficient p-value.)\nThe remaining information (Residual standard error, degrees of freedom, Multiple R-squared, Adjusted R-squared, F-statistic, and p-value) is beyond this introductory workshop. Just know that the p-value reported here is almost useless.\nIn contrast, the coefficient p-values, reported as Pr(&gt;|t|) in the Coefficients: table, are often the main focus of analysis. Making use of these p-values and interpreting the asterisks as indicators of statistical significance depends on proper use of the lm() function. In particular, you must decide which variables to use before fitting a model, and you can only try once - otherwise, the p-values will be biased by peeking at the result before doing the test."
  },
  {
    "objectID": "02_linear_model.html#assumptions-of-linear-regression",
    "href": "02_linear_model.html#assumptions-of-linear-regression",
    "title": "3  Linear Regression",
    "section": "3.4 Assumptions of linear regression",
    "text": "3.4 Assumptions of linear regression\nThere are a few assumptions about your data that come with linear regression. Before you can accept the results, you must check these:\n\nLinearity: The actual relationship between the features and the response is linear. A trend in the fitted vs. residual plot is evidence that the linearity assumption may be wrong.\nNormality: Check that the residuals have a normal distribution. You can check this via the Q-Q plot, which should have all the dots in an approximately straight line.\nConstant/equal residual variance: The residuals should have the same variability, also called the scale. Confirm this by the location-scale plot.\nIndependence: The residuals must be independent of each other. You can’t actually check this from the data, so you have to think carefully about how the value of one residual might depend upon others (for instance if they are measured at locations that touch, maybe there is something that affects both.) Data collection should be planned in order to have independent responses.\n\nLet’s check the assumptions on the penguin body size model:\n\nlayout(matrix(1:4, 2, 2))\nplot(penguin_mass_model)\n\n\n\n\nHere, there is a slight “U” shape in the Residual vs Fitted plot and in the Q-Q plot, which indicates that the relationship between flipper length and body mass is not quite linear. The points fall very close to the dashed diagonal on the Q-Q plot, which indicates that the residuals all seem to be from a nearly identical normal distribution. There is no clear pattern in the scale-location plot, so the residual variances are approximately equal. The deviations from ideal are pretty minor, and you could probably rely on this model to predict the mass of new penguins. But a more correct model is possible by looking at the species separately, as we’ll see in the next chapter."
  },
  {
    "objectID": "02_linear_model.html#multiple-features",
    "href": "02_linear_model.html#multiple-features",
    "title": "3  Linear Regression",
    "section": "3.5 Multiple features",
    "text": "3.5 Multiple features\nOur example above has just a single feature to create a model for the response. It is more common to have multiple features, and there really is no limit to how many. However, if the number of features is greater than the number of observations, then we will have problems with the estimation methods.\nWhen there are multiple features, they may be correlated with each other. This is almost always true of observational data (which are features that are measured from the observed units). Typically, the only way to have perfectly uncorrelated data is by designing an experiment where the treatments are uncorrelated.\nCorrelated features will affect each others’ estimates, and the effect increases with the amount of correlation. That happens because when features are correlated, the model has similar fits if one coefficient increases and the other decreases, or vice versa.\nWe can reasonably assume that penguins with longer flippers and heavier bodies also have longer bills. That’s true, as seen in this figure:\n\n\nCode\nbill_plot_1 = ggplot(penguins) +\n  aes(x=flipper_length_mm, y=bill_length_mm) +\n  geom_point() +\n  xlab(\"Flipper length (mm)\") +\n  ylab(\"Bill length (mm)\")\n\nbill_plot_2 = ggplot(penguins) +\n  aes(x=body_mass_g, y=bill_length_mm) +\n  geom_point() +\n  xlab(\"Body mass (g)\") +\n  ylab(\"Bill length (mm)\")\n\ncowplot::plot_grid(bill_plot_1, bill_plot_2, ncol=2)\n\n\n\n\n\nAs a result, including the bill length as a second feature in the model for body mass leads to a change in the estimated regression coefficient for flipper length and an increase in the uncertainty for that estimate:\n\ncorrelated_model = lm(\n  body_mass_g ~ flipper_length_mm + bill_length_mm,\n  data=penguins)\nsummary(correlated_model)\n\n\nCall:\nlm(formula = body_mass_g ~ flipper_length_mm + bill_length_mm, \n    data = penguins)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-1090.5  -285.7   -32.1   244.2  1287.5 \n\nCoefficients:\n                   Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)       -5736.897    307.959 -18.629   &lt;2e-16 ***\nflipper_length_mm    48.145      2.011  23.939   &lt;2e-16 ***\nbill_length_mm        6.047      5.180   1.168    0.244    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 394.1 on 339 degrees of freedom\n  (2 observations deleted due to missingness)\nMultiple R-squared:   0.76, Adjusted R-squared:  0.7585 \nF-statistic: 536.6 on 2 and 339 DF,  p-value: &lt; 2.2e-16\n\n\nThe estimated coefficient has changed from 49.7 to round(coef(correlated_model)[[2]], 1) and the standard error of the estimated coefficient for flipper_length_mm is 2, which is 32% greater than the previous standard error of 1.5.\n\n3.5.1 Which features to include?\nA common question is how to decide which features to include in a model. There’s no definitive answer, since the “best” model depends on the goal of the analysis, and model selection frequently ends in marginal and somewhat subjective decisions. In the simplest terms, the correct features for your model are the ones that are relevant to your analysis.\nIf your goal is to study the relationship between some specific features and the response, then it’s best to select those features before fitting a model, and of course you have to keep in mind assumption (1) for linear models: “The actual relationship between the features and the response is linear.” This is a theory-driven approach to model selection, because you begin with an idea of the model you want to fit, and then tell the computer to estimate it.\nThere are data-driven ways of doing model selection, most of which can be summarized as: try a model and then change it to get a better fit. These approaches are dangerous because they tend to over-fit the training data, which usually makes the model less useful for future data. In order to mitigate that risk, a portion of the data has to be held out from the model fitting, to test the model with."
  },
  {
    "objectID": "03_categorical_continuous.html#factors",
    "href": "03_categorical_continuous.html#factors",
    "title": "4  Categorical features",
    "section": "4.1 Factors",
    "text": "4.1 Factors\nIn R, categorical variables are called factors. Deep down in the machinery of a regression model, factor effects are handled the same way as continuous features. To fully appreciate this, you have to understand that factors are coded differently than continuous features. To begin, note that linear regression for factor variables is also a kind of scatterplot smoother. Let’s look at an example:\n\n4.1.1 Penguin body mass\nReturning to the palmerpenguins dataset, the plot below shows the mass of penguins of three different species.\n\n\nCode\nggplot(penguins) +\n  aes(x=species, y=body_mass_g) +\n  geom_point() +\n  ggtitle(\"Body mass of penguins by species\") +\n  ylab(\"Mass (g)\")\n\n\n\n\n\nLook carefully at the x-axis and you’ll see that the coordinates are species names, not numbers. A line drawn to fit the points would imply that there is an order to the species, and that there are some intermediate values between the species.\n\n\nCode\nggplot(penguins) +\n  aes(x=species, y=body_mass_g) +\n  geom_point() +\n  geom_abline(intercept=1800, slope=1200, color=\"blue\") +\n  ggtitle(\"Body mass of penguins by species with linear fit\") +\n  ylab(\"Mass (g)\")\n\n\n\n\n\nClearly, we need to treat the species as categories, rather than as coordinates along a continuum. Looking at the summary of a regression model gives a clue as to how that works.\n\npenguin_lm = lm(body_mass_g ~ species, data=penguins)\nsummary(penguin_lm)\n\n\nCall:\nlm(formula = body_mass_g ~ species, data = penguins)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-1126.02  -333.09   -33.09   316.91  1223.98 \n\nCoefficients:\n                 Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)       3700.66      37.62   98.37   &lt;2e-16 ***\nspeciesChinstrap    32.43      67.51    0.48    0.631    \nspeciesGentoo     1375.35      56.15   24.50   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 462.3 on 339 degrees of freedom\n  (2 observations deleted due to missingness)\nMultiple R-squared:  0.6697,    Adjusted R-squared:  0.6677 \nF-statistic: 343.6 on 2 and 339 DF,  p-value: &lt; 2.2e-16\n\n\nNow let’s see the mean masses of the three species.\n\ngroup_by(penguins, species) |&gt;\n  summarize(mass = mean(body_mass_g, na.rm=TRUE))\n\n# A tibble: 3 × 2\n  species    mass\n  &lt;fct&gt;     &lt;dbl&gt;\n1 Adelie    3701.\n2 Chinstrap 3733.\n3 Gentoo    5076.\n\n\nNotice that the fitted value of the (Intercept) is identical to the average mass of an Adelie penguin, and that there are two rows of species effects, instead of the one row that we saw for the continuous effects so far. The values of the Estimate column in those rows are the estimated effects for Chinstrap and Gentoo penguins - and they are equal to the difference between the average mass of those penguins and Adelie penguins.\n\n\n4.1.2 Design matrix\nThe reason that the results look like this can be made more clear if you look at the way R converts the categories to numbers. The model.matrix() is the function that R uses internally to prepare data for an lm(), but we can call it ourselves. Remember that linear regression works by multiplying each term by a coefficient, adding adding the results together. Here, we have three terms for the three species. Adelie has been automatically selected as the reference level because it appears first in the data.\n\ntail(model.matrix(penguin_lm))\n\n    (Intercept) speciesChinstrap speciesGentoo\n339           1                1             0\n340           1                1             0\n341           1                1             0\n342           1                1             0\n343           1                1             0\n344           1                1             0\n\n\nHere, we have three terms: (Intercept), speciesChinstrap, and speciesGentoo. So to calculate the mass that is estimated for row 12, we will add 1 * (Intercept) + 1 * speciesGentoo. Since the effect (Intercept) is the average mass of the Adelie penguins, the effect speciesGentoo must be the difference between the mean mass of Gentoo penguins and the mean mass of Adelie penguins. Why no term for speciesAdelie? It’s because the fit would then depend on how mass was apportioned between the penguin species and the intercept. You could increase the intercept by 10 grams and reduce all three species estimates by 10 grams and end up with the same model fit, despite different effects. The computer has no way of deciding between those options, because it is just minimizing the model error.\nYou don’t have to set one factor level to be the reference for estimation, but that goes beyond the scope of this introductory workshop. You may need to change which level is the reference, and that is within our scope. R has a function relevel(), which takes the argument ref=, which specifies the reference level of a factor. Here is how it would work to set Gentoo as the reference level:\n\npenguins$species = relevel(penguins$species, ref=\"Gentoo\")\nreleveled_penguin_model = lm(body_mass_g ~ species, data=penguins)\nsummary(releveled_penguin_model)\n\n\nCall:\nlm(formula = body_mass_g ~ species, data = penguins)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-1126.02  -333.09   -33.09   316.91  1223.98 \n\nCoefficients:\n                 Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)       5076.02      41.68  121.78   &lt;2e-16 ***\nspeciesAdelie    -1375.35      56.15  -24.50   &lt;2e-16 ***\nspeciesChinstrap -1342.93      69.86  -19.22   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 462.3 on 339 degrees of freedom\n  (2 observations deleted due to missingness)\nMultiple R-squared:  0.6697,    Adjusted R-squared:  0.6677 \nF-statistic: 343.6 on 2 and 339 DF,  p-value: &lt; 2.2e-16\n\n\nWith Gentoo as the reference level for species, the summary of model results tells us directly that the body mass of Adelie and Chinstrap penguins are both significantly less than that of Gentoo penguins. However we set the factor levels, the model predictions remain unchanged, which helps emphasize that the factor coding affects which interpretation(s) are emphasized in the summary but does not change the model.\n\n# compare predictions between the models with different contrasts:\npred_df = data.frame(species=c(\"Adelie\", \"Chinstrap\", \"Gentoo\"))\npredict(penguin_lm, pred_df)\n\n       1        2        3 \n3700.662 3733.088 5076.016 \n\npredict(releveled_penguin_model, pred_df)\n\n       1        2        3 \n3700.662 3733.088 5076.016"
  },
  {
    "objectID": "03_categorical_continuous.html#combining-continuous-and-categorical",
    "href": "03_categorical_continuous.html#combining-continuous-and-categorical",
    "title": "4  Categorical features",
    "section": "4.2 Combining continuous and categorical",
    "text": "4.2 Combining continuous and categorical\nOf course, continuous and categorical features don’t have to be kept separate. We’ll return to our original example and consider whether the relationship between a penguin’s mass and its flipper length is different between the three species. You combine categorical and continuous features by adding them together in the model formula.\n\n# create a model with both species and flipper length as features\ncombo_model = lm(body_mass_g ~ flipper_length_mm + species,\n     data=penguins)\n\nHere is a visualization of the model fit:\n\n\nCode\npenguins$nointeract = predict(combo_model, newdata=penguins)\nggplot(penguins) +\n  aes(x=flipper_length_mm, y=body_mass_g, color=species) +\n  geom_point() +\n  xlab(\"Flipper length (mm)\") +\n  ylab(\"Penguin mass (g)\") +\n  geom_smooth(data=penguins,\n                mapping=aes(x=flipper_length_mm, y=nointeract, color=species),\n                method='lm',\n                se=FALSE)\n\n\n\n\n\nAs you can see, adding a categorical factor to the model has resulted in a vertical offset between the regression lines for each species, and the three regression lines all have the same slope. You should therefore interpret the species effects as species-specific intercepts for the regression line. Now, let’s generate the summary plots and the model summary.\n\n# plot the model diagnostics\nlayout(matrix(1:4, 2, 2))\nplot(combo_model)\n\n\n\n# check out the model summary\nsummary(combo_model)\n\n\nCall:\nlm(formula = body_mass_g ~ flipper_length_mm + species, data = penguins)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-927.70 -254.82  -23.92  241.16 1191.68 \n\nCoefficients:\n                   Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)       -3764.667    667.844  -5.637 3.65e-08 ***\nflipper_length_mm    40.705      3.071  13.255  &lt; 2e-16 ***\nspeciesAdelie      -266.810     95.264  -2.801  0.00539 ** \nspeciesChinstrap   -473.320     86.746  -5.456 9.41e-08 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 375.5 on 338 degrees of freedom\n  (2 observations deleted due to missingness)\nMultiple R-squared:  0.7826,    Adjusted R-squared:  0.7807 \nF-statistic: 405.7 on 3 and 338 DF,  p-value: &lt; 2.2e-16\n\n\nThe summary shows how big the differences are between the species-specific intercepts. The diagnostic plots still exhibit a “U” shape in the Fitted Vs. Residual plot, so we haven’t yet found an ideal regression model for this data."
  },
  {
    "objectID": "03_categorical_continuous.html#interactions",
    "href": "03_categorical_continuous.html#interactions",
    "title": "4  Categorical features",
    "section": "4.3 Interactions",
    "text": "4.3 Interactions\nWe can improve this model further by adding an interaction between the species and the flipper length. An interaction allows the regression lines to have different slopes for the different species, as seen here:\n\n\nCode\nggplot(penguins) +\n  aes(x=flipper_length_mm, y=body_mass_g, color=species) +\n  geom_point() +\n  xlab(\"Flipper length (mm)\") +\n  ylab(\"Penguin mass (g)\") +\n  geom_smooth(method='lm', se=FALSE)\n\n\n\n\n\nThere will still be different intercepts between species because I have retained the so-called “main effect” of species. An intercept is written in an R formula by placing a colon (:) between two variables.\n\n# create a model interacting species and flipper length as features\ninteraction_model =\n  lm(body_mass_g ~ flipper_length_mm + species + flipper_length_mm:species,\n     data=penguins)\n\nAnd now we can look at the diagnostics.\n\n# plot the model diagnostics\nlayout(matrix(1:4, 2, 2))\nplot(interaction_model)\n\n\n\n# check out the model summary\nsummary(interaction_model)\n\n\nCall:\nlm(formula = body_mass_g ~ flipper_length_mm + species + flipper_length_mm:species, \n    data = penguins)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-911.18 -251.93  -31.77  197.82 1144.81 \n\nCoefficients:\n                                    Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)                        -6787.281   1124.195  -6.037 4.14e-09 ***\nflipper_length_mm                     54.623      5.174  10.557  &lt; 2e-16 ***\nspeciesAdelie                       4251.444   1427.332   2.979  0.00311 ** \nspeciesChinstrap                    3750.085   1676.687   2.237  0.02597 *  \nflipper_length_mm:speciesAdelie      -21.791      6.941  -3.139  0.00184 ** \nflipper_length_mm:speciesChinstrap   -20.049      8.190  -2.448  0.01487 *  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 370.6 on 336 degrees of freedom\n  (2 observations deleted due to missingness)\nMultiple R-squared:  0.7896,    Adjusted R-squared:  0.7864 \nF-statistic: 252.2 on 5 and 336 DF,  p-value: &lt; 2.2e-16\n\n\nThe “U” shape in the residuals is gone! Also, the significantly negative coefficients for the interactions of flipper length with species Adelie and Chinstrap tells us that body mass for these species increases less quickly with flipper length than for Gentoo penguins. You can see this same relationship in the steeper slope of the red line in the scatter plot with interactions."
  },
  {
    "objectID": "04_generalized_linear_model.html#poisson-regression---effectiveness-of-bug-sprays",
    "href": "04_generalized_linear_model.html#poisson-regression---effectiveness-of-bug-sprays",
    "title": "5  Generalized Linear Models",
    "section": "5.1 Poisson Regression - Effectiveness of Bug Sprays",
    "text": "5.1 Poisson Regression - Effectiveness of Bug Sprays\nWe conclude with an example using count data as a response. The InsectSprays dataset is built in to R so you can import it with the command data(InsectSprays). It has 72 observations of two features. The two features are: the type of insecticide that was applied to a plant, and the other is a count of how many insects were found on the plant. Our goal is to determine whether the different insecticides lead to a consistent difference in the number of insects.\nPlotting the data reveals that there are six insecticides in the study, with twelve observations each:\n\ndata(InsectSprays)\nplot(InsectSprays)\n\n\n\n\nWe can see a few more things from the plot. Counts range from zero to 26, and it appears that the insecticides are in two groups: the counts for sprays 3, 4, and 5 are clustered at low counts (ony one count in this group is greater than six), while the counts for sprays 1, 2, and 6 are all at least seven. That suggests that there is a significant difference between the treatments.\nWe can also see that the counts are more densely clustered for the lesser counts, and more spread out for the greater counts. That’s an unequal variance, so the linear model is probably not appropriate. There is a response type specifically for count data that gets more spread out as the average count grows: Poisson. Let’s fit a Poisson regression to the insecticide data.\n\nmodel_spray = glm(count ~ spray, data=InsectSprays, family='poisson')\nsummary(model_spray)\n\n\nCall:\nglm(formula = count ~ spray, family = \"poisson\", data = InsectSprays)\n\nCoefficients:\n            Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)  2.67415    0.07581  35.274  &lt; 2e-16 ***\nsprayB       0.05588    0.10574   0.528    0.597    \nsprayC      -1.94018    0.21389  -9.071  &lt; 2e-16 ***\nsprayD      -1.08152    0.15065  -7.179 7.03e-13 ***\nsprayE      -1.42139    0.17192  -8.268  &lt; 2e-16 ***\nsprayF       0.13926    0.10367   1.343    0.179    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for poisson family taken to be 1)\n\n    Null deviance: 409.041  on 71  degrees of freedom\nResidual deviance:  98.329  on 66  degrees of freedom\nAIC: 376.59\n\nNumber of Fisher Scoring iterations: 5\n\n# make diagnostic plots:\ndeviance_residuals = residuals(model_spray, type=\"deviance\")\nlayout(matrix(1:2, 1, 2))\nqqnorm(deviance_residuals)\nabline(a=0, b=1, lty=3)\nplot(fitted(model_spray), deviance_residuals)\n\n\n\n\nThe diagnostics for this model look pretty good. The Q-Q plot may indicate slightly heavy tails, which would be a sign that the response is overdispersed for the Poisson distribution. A further check is to calculate the mean and variance for each group in the data (this is ony pratical because the model is simple and the number of levels is small). If the data has a Poisson distribution, we expect that the mean and the variance are approximately equal. Of course, real data never perfectly matches this expected relationship.\n\n# check the men-variance relationship\ngroup_by(InsectSprays, spray) |&gt;\n  summarize(mean = mean(count),\n            var = var(count))\n\n# A tibble: 6 × 3\n  spray  mean   var\n  &lt;fct&gt; &lt;dbl&gt; &lt;dbl&gt;\n1 A     14.5  22.3 \n2 B     15.3  18.2 \n3 C      2.08  3.90\n4 D      4.92  6.27\n5 E      3.5   3   \n6 F     16.7  38.6 \n\n\nIn most cases, the variance is slightly greater than the mean. Only group F has variance more than twice the mean, which is a reasonable threshold for where to begin to worry.\n\n5.1.1 Negative-binomial regression\nI’d probably leave the InsectSprays model as it is for simplicity, but it would also be reasonable to change the model to account for overdispersion. There are a lot of ways to do that, and one classic method is to model the response as a negative-binomial distribution. That requires loading the MASS package, which provies the glm.nb() function. Here’s the result:\n\n# import the MASS package\nlibrary(MASS)\n\n\nAttaching package: 'MASS'\n\n\nThe following object is masked from 'package:dplyr':\n\n    select\n\n#estimate the NB model\nmodel_spray_nb = glm.nb(count ~ spray, data=InsectSprays)\nsummary(model_spray_nb)\n\n\nCall:\nglm.nb(formula = count ~ spray, data = InsectSprays, init.theta = 28.09950714, \n    link = log)\n\nCoefficients:\n            Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)  2.67415    0.09334  28.649  &lt; 2e-16 ***\nsprayB       0.05588    0.13082   0.427    0.669    \nsprayC      -1.94018    0.22733  -8.535  &lt; 2e-16 ***\nsprayD      -1.08152    0.16920  -6.392 1.64e-10 ***\nsprayE      -1.42139    0.18838  -7.545 4.52e-14 ***\nsprayF       0.13926    0.12914   1.078    0.281    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for Negative Binomial(28.0995) family taken to be 1)\n\n    Null deviance: 313.444  on 71  degrees of freedom\nResidual deviance:  74.145  on 66  degrees of freedom\nAIC: 374.22\n\nNumber of Fisher Scoring iterations: 1\n\n              Theta:  28.1 \n          Std. Err.:  17.7 \n\n 2 x log-likelihood:  -360.218 \n\n# make diagnostic plots:\ndeviance_residuals_nb = residuals(model_spray_nb, type=\"deviance\")\nlayout(matrix(1:2, 1, 2))\nqqnorm(deviance_residuals_nb)\nabline(a=0, b=1, lty=3)\nplot(fitted(model_spray_nb), deviance_residuals_nb)\n\n\n\n# compare the models on the basis of AIC\nAIC(model_spray, model_spray_nb)\n\n               df      AIC\nmodel_spray     6 376.5892\nmodel_spray_nb  7 374.2179\n\n\nThe negative-binomial model has a smaller AIC and the Q-Q lies more along the line. We should conclude that the negative-binomial model appears to be a slightly better fit for the data."
  },
  {
    "objectID": "05_fixed_random_effects.html#hierarchical-data",
    "href": "05_fixed_random_effects.html#hierarchical-data",
    "title": "6  Random and Mixed Effects",
    "section": "6.1 Hierarchical data",
    "text": "6.1 Hierarchical data\nReal-world science often sees data grouped according to some known structure of the study. For instance, in an agricultural experiment, the yield of crops from the same field is generally more alike than crops from different fields, even if all fields in question received the same treatment. Why? Maybe the soil was generally better quality in one field, or one got more rain than the other, or the treatments weren’t applied with perfect consistency across fields.\nIn order to account for factors like these, agricultural researchers divide fields into plots and apply a different treatment to each plot. This is an example of hierarchical data: there are measurements of crop yields for each plot in a field. We say that the plots are nested within the fields, and that the field ID is a grouping feature in the data."
  },
  {
    "objectID": "05_fixed_random_effects.html#is-my-effect-fixed-or-random",
    "href": "05_fixed_random_effects.html#is-my-effect-fixed-or-random",
    "title": "6  Random and Mixed Effects",
    "section": "6.2 Is my effect fixed? Or random?",
    "text": "6.2 Is my effect fixed? Or random?\nHierarchical grouping features can be modeled with either fixed or random effects. The choice depends on your intended interpretation. If you will have a reason to read the estimated coefficient off the summary table, then that’s a fixed effect. If the grouping feature is only included so you can account for structure in the data, then that’s a random effect. Random effects appear both in designed experiments and in observational studies. We’ve mentioned that the measured yield in an agricultural experiment usually depends on the specific conditions of each field. But when an experiment has identified the best way to grow a crop, it will be applied to fields that weren’t in the study. In that case, we care how different the yields will be in random fields that come from the population of farm fields, not the specific fields that were used in the experiment. This is a classic example of a random effect.\nA side note: random effects models make more intuitive sense if you think like a Bayesian. For each level of the grouping feature, sample its effect from a random distribution (which almost always has a Normally distributed prior distribution), and then use the sampled effect in the model for the observed response. This two (or more) step process should match the levels of the hierarchy in the data."
  },
  {
    "objectID": "05_fixed_random_effects.html#example-oat-yields",
    "href": "05_fixed_random_effects.html#example-oat-yields",
    "title": "6  Random and Mixed Effects",
    "section": "6.3 Example: oat yields",
    "text": "6.3 Example: oat yields\nNow we will analyze just such an experiment, which tests the production of three varieties of oats grown with four different quantities of nitrogen fertilizer. Together, we call the variety and the nitrogen treatments because they are conditions of he experiment that are in our control. The goal is to identify varieties and fertilizers that consistently generate a greater yield of oats than the others.\nIn order to identify a consistent difference between treatment combinations, we need to replicate the treatments in multiple experimental units. That’s because without replication we will not know whether any differences we observe are due to the treatments or to natural variability (no matter how careful you are to treat plots the same, you cannot grow exactly the same quantity of oats twice).\nHow can you achieve replication? If you randomly choose a few areas to measure from within the same plot, then you can estimate the way that parts of a plot differ from each other. Generally this is not very useful because you will go on to grow the oats in different plots than the one in the experiment, and the differences between parts of the same plot are likely to be smaller than the differences between entirely separate plots.\nSo in order to accurately estimate how different the yields will be when the oats are grown by farmers instead of experimenters, the experimenters must replicate each treatment in units that are relevant to the farmers - in this case, that means planting multiple plots with each combination of variety and nitrogen. The actual growing conditions will differ slightly even between plots that were given the same treatment and we want to estimate how big those differences are in practice.\nIn this case the plots are assigned to blocks, which are a group of plots that are linked somehow. In this case blocks are locations, which helps ensure each block has consistent soil and environmental conditions.\n\n6.3.1 The oats data\nWe are finally ready to look at the data.\n\nlibrary(MASS)\ndata(oats)\nsummary(oats)\n\n   B                V           N            Y        \n I  :12   Golden.rain:24   0.0cwt:18   Min.   : 53.0  \n II :12   Marvellous :24   0.2cwt:18   1st Qu.: 86.0  \n III:12   Victory    :24   0.4cwt:18   Median :102.5  \n IV :12                    0.6cwt:18   Mean   :104.0  \n V  :12                                3rd Qu.:121.2  \n VI :12                                Max.   :174.0  \n\n\nThe oats data frame has five columns and 72 rows. Yield (Y, in pounds) will be the response. As features, there are three varieties (V), six blocks (B), and four numerical nitrogen treatments (N). I’ve included a picture of the first 28 rows of data to show you how the data is structured for a random effect.\n\n\n\nPicture of the first 28 rows of the oats data set, with shading used to indicate the rows that belong to the same block (B)\n\n\nThe nitrogen treatments are in hundredweight (cwt) per acre, which is a numerical value, but are written as characters. So we will need to convert those to numeric by taking the first three characters.\n\n# convert nitrogen to numeric\noats$nitrogen = as.numeric(substr(oats$N, 1, 3))\n\nNow let’s look at a plot of the data:\n\n\nCode\nggplot(oats) +\n  aes(x=nitrogen, y=Y, color=V) +\n  geom_point() +\n  facet_wrap(~B, ncol=3) +\n  xlab(\"Nitrogen (cwt/acre)\") +\n  ylab(\"Yield (pounds)\") +\n  ggtitle(\"Yield of oats per plot (1/160 acre)\")\n\n\n\n\n\nEach facet depicts the data from one block. There are apparent differences between blocks and an increasing trend of yield with nitrogen. The trend looks like it could be linear. If there is a consistent difference in yield between the varieties, it is small.\nSo block matters, even though it is not of interest in the analysis. Treatments were applied and measured at the plot level, so there is one observation per experimental unit. These observations are only independent after accounting for the block grouping - remember that regression assumes the residuals are independent.\n\n\n6.3.2 Fixed-effects model\nBefore stepping into a mixed-effects example, I’d like to show you what it looks like if we model the data using fixed effects for everything. I’ll present the summary but not the diagnostic plots in order to save time.\n\n# estimate the fixed-effects model\noats_fixed_model = lm(Y ~ nitrogen + V + B, data=oats)\nsummary(oats_fixed_model)\n\n\nCall:\nlm(formula = Y ~ nitrogen + V + B, data = oats)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-30.519 -12.959   0.781  10.706  34.631 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  113.761      5.652  20.126  &lt; 2e-16 ***\nnitrogen      73.667      8.075   9.123 3.97e-13 ***\nVMarvellous    5.292      4.423   1.196    0.236    \nVVictory      -6.875      4.423  -1.554    0.125    \nBII          -28.083      6.255  -4.490 3.10e-05 ***\nBIII         -39.417      6.255  -6.302 3.23e-08 ***\nBIV          -37.167      6.255  -5.942 1.33e-07 ***\nBV           -44.417      6.255  -7.101 1.33e-09 ***\nBVI          -39.083      6.255  -6.249 3.99e-08 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 15.32 on 63 degrees of freedom\nMultiple R-squared:  0.7155,    Adjusted R-squared:  0.6794 \nF-statistic: 19.81 on 8 and 63 DF,  p-value: 1.507e-14\n\n\nThis summary should by now look familiar. As usual we will ignore the Call and Residuals sections. There are coefficient estimates for one intercept, a slope for nitrogem two varieties, and five blocks. Recall that there are three varieties and six blocks: the reference level for each of these categorical features has been included in the intercept. Later, we will return to the coefficient estimates and the residual standard error.\n\n\n6.3.3 Mixed-effects model\nWe will treat block as a random effect because the blocks are a random sample from the population of blocks where the oats may ultimately be grown, each of which will have its own localized growing conditions. Our random effects analysis allows us to estimate how much of the variability in oat harvest would be due to differences between blocks, vs. differences in nitrogen and variety of oats (which are our fixed effects because they are consistent across blocks).\n\n6.3.3.1 Software to estimate the model\nThere are several R packages that implement random effects in regression. lme4 is the most-used and brms is the Bayesian equivalent, which also offers some great features that aren’t available in lme4. Both of them use a formula syntax similar to the lm() and glm() functions that you’ve already seen. The only difference is that the random effects need to be specified using a special notation: they are written as two parts wrapped in parentheses. The first part indicates the effect that changes with the grouping factor, and the second part indicates what variable is the grouping factor.\n\n# create a mixed-effects model for oats\noats_model = lmer(Y ~ nitrogen + V + (1|B), data=oats)\n\n# make the residual vs fitted plot for the model:\nfit_v_resid_oats = plot(oats_model)\n\n# make the QQ plot:\nqq_oats = lattice::qqmath(oats_model)\n\n# draw the plots\ncowplot::plot_grid(fit_v_resid_oats, qq_oats, ncol=2)\n\n\n\n# show the model summary\nsummary(oats_model)\n\nLinear mixed model fit by REML ['lmerMod']\nFormula: Y ~ nitrogen + V + (1 | B)\n   Data: oats\n\nREML criterion at convergence: 588\n\nScaled residuals: \n     Min       1Q   Median       3Q      Max \n-1.84069 -0.80849  0.04022  0.70484  2.22148 \n\nRandom effects:\n Groups   Name        Variance Std.Dev.\n B        (Intercept) 245.0    15.65   \n Residual             234.7    15.32   \nNumber of obs: 72, groups:  B, 6\n\nFixed effects:\n            Estimate Std. Error t value\n(Intercept)   82.400      7.516  10.964\nnitrogen      73.667      8.075   9.123\nVMarvellous    5.292      4.423   1.196\nVVictory      -6.875      4.423  -1.554\n\nCorrelation of Fixed Effects:\n            (Intr) nitrgn VMrvll\nnitrogen    -0.322              \nVMarvellous -0.294  0.000       \nVVictory    -0.294  0.000  0.500\n\n\nThe residual vs fitted plot has a bit of a fan shape and the QQ plot is not perfect. Maybe there is a better model? More on that later.\n\n\n\n6.3.4 Interpretation\nFirst, let’s look at the layout of the summary for a mixed-effects model, beginning with the parts that are already familiar. In the picture below, I’ve highlighted the Call (Green), Residuals (Purple), and Fixed Effects (Red) sections of the lmer() model summary. These are just about the same as the sections in the lm() model summary except that there are no p-values in the Fixed Effects table (due to a philosophical choice by the lme4 package developers).\n\n\n\nSummary output of a mixed-effects model, with boxes highlighting the Call, Residuals, and Fixed Effects sections\n\n\nWith those out of the way, let’s now look at the parts of the model summary that are new. The REML criterion at convergence is not interesting to us. The correlation of fixed effects is rarely interesting. The only new and useful information, then, is the summary of random effects.\nAgain, let’s eliminate the parts that we already know about. The bottom line reports that there are 72 observations and six blocks. Ok, we knew that. What’s left is a table that kind of looks like the fixed effect summary. We’ve got rows for B and Residual, which the table header tells us are called Groups.\nB is there because the data are grouped by the blocks. Since that is the only grouping feature, any other variance must be assigned to the individual observations, which we saw in Chapter 2 is called residual variance — hence the name. The random effect for B is a random intercept (more about that later). That leaves two columns, Variance and Std.Dev.. Standard deviation is the square root of variance so these columns are telling us the same thing and we can ignore one of them. Standard deviation is more interesting because it is telling us the typical difference in the yield between blocks (row B), as well as the typical residual error (row Residual).\nWhile the fixed effects section has the same meaning as the table of coefficient estimates from a fixed-effects model, there is one important difference in the table’s contents: the fixed effects section includes only the intercept, two varieties, and the slope for nitrogen. Blocks are gone from the fixed effects and are instead included in random effects, due to how we specified the model. Despite this difference, the actual fixed effects coefficients and their standard errors are identical to those for the old fixed-effects model. This is not a general feature of mixed-effects models! It happens here because the model is perfectly balanced, which means that each combination of variety, nitrogen, and block has exactly the same number of observations. Try re-estimating the models after removing some rows from oats at random to see how the estimates change in the two models.\n\n\n6.3.5 Visualize the fitted model\nWe have allowed a random intercept for each block, which applies to all of the plots within the block. So, the fitted model should have the same slopes and variety effects in each block, but with a block effect that shifts the regression lines up or down to account for between-block differences. Here is the plot of the data, overlaid with lines to represent the fitted model:\n\n# attach a column of fitted values to the oats data.frame\noats$fitted = predict(oats_model, newdata=oats)\n\n# plot the data with the fitted model lines\nggplot(oats) +\n  aes(x=nitrogen, y=Y, color=V) +\n  geom_point() +\n  geom_line(mapping=aes(x=nitrogen, y=fitted, color=V)) +\n  facet_wrap(~B, ncol=3) +\n  xlab(\"Nitrogen (cwt/acre)\") +\n  ylab(\"Yield (pounds)\") +\n  ggtitle(\"Model for yield of oats per plot (1/160 acre)\")"
  },
  {
    "objectID": "05_fixed_random_effects.html#example-sleep-study",
    "href": "05_fixed_random_effects.html#example-sleep-study",
    "title": "6  Random and Mixed Effects",
    "section": "6.4 Example: sleep study",
    "text": "6.4 Example: sleep study\nNow let’s look at a different example. Sleep scientists enrolled 18 subjects and kept them in a controlled habitat for ten days. The subjects were only allowed to spend three hours in bed each night, and their reflex reaction time was measured daily.\n\n6.4.1 The sleepstudy data\nThis data is available in the lme4 package, which you have already imported. Let’s load the data and look at it.\n\ndata(sleepstudy)\nhead(sleepstudy, n=20)\n\n   Reaction Days Subject\n1  249.5600    0     308\n2  258.7047    1     308\n3  250.8006    2     308\n4  321.4398    3     308\n5  356.8519    4     308\n6  414.6901    5     308\n7  382.2038    6     308\n8  290.1486    7     308\n9  430.5853    8     308\n10 466.3535    9     308\n11 222.7339    0     309\n12 205.2658    1     309\n13 202.9778    2     309\n14 204.7070    3     309\n15 207.7161    4     309\n16 215.9618    5     309\n17 213.6303    6     309\n18 217.7272    7     309\n19 224.2957    8     309\n20 237.3142    9     309\n\n\nThere are three columns and 180 rows. The response, Reaction, is numeric, as is the Days feature. Subject refers to a person in the study, so even though the data are numbers, we should treat them as categories. As usual, let’s plot the data.\n\n\nCode\n# Create a scatterplot of fitted reaction times against Days\nggplot(sleepstudy) +\n  aes(x = Days, y = Reaction, color = Subject) +\n   geom_point() \n\n\n\n\n\nCode\n   labs(title = \"Reaction time vs. days by subject\",\n        x = \"Days of sleep deprivation\",\n        y = \"Reaction time (ms)\")\n\n\n$x\n[1] \"Days of sleep deprivation\"\n\n$y\n[1] \"Reaction time (ms)\"\n\n$title\n[1] \"Reaction time vs. days by subject\"\n\nattr(,\"class\")\n[1] \"labels\"\n\n\nThere is clearly a trend where the reaction time gets longer as more days of sleep deprivation accumulate.\n\n\n6.4.2 Random intercept model\nThe goal of the study is to analyze the relationship between days of sleep deprivation and reaction time. So the slope of Days will be estimated as a fixed effect. Observations are grouped within subjects, and we are more interested in the typical differences between individuals than in the reaction times of the specific people who were subjects in this study. So Subject will be a random effect in the model. Let’s begin with the model:\n\n# estimate the reaction time model\nreaction_model = lmer(Reaction ~ Days + (1|Subject), data=sleepstudy)\n\n#show the model summary\nsummary(reaction_model)\n\nLinear mixed model fit by REML ['lmerMod']\nFormula: Reaction ~ Days + (1 | Subject)\n   Data: sleepstudy\n\nREML criterion at convergence: 1786.5\n\nScaled residuals: \n    Min      1Q  Median      3Q     Max \n-3.2257 -0.5529  0.0109  0.5188  4.2506 \n\nRandom effects:\n Groups   Name        Variance Std.Dev.\n Subject  (Intercept) 1378.2   37.12   \n Residual              960.5   30.99   \nNumber of obs: 180, groups:  Subject, 18\n\nFixed effects:\n            Estimate Std. Error t value\n(Intercept) 251.4051     9.7467   25.79\nDays         10.4673     0.8042   13.02\n\nCorrelation of Fixed Effects:\n     (Intr)\nDays -0.371\n\n\nAnd let’s check the diagnostic plots:\n\n\nCode\n# make the residual vs fitted plot for the model:\nfit_v_resid_sleep = plot(reaction_model)\n\n# make the QQ plot:\nqq_sleep = lattice::qqmath(reaction_model)\n\n# draw the plots\ncowplot::plot_grid(fit_v_resid_sleep, qq_sleep, ncol=2)\n\n\n\n\n\nThere is a clear fan-shape in the residuals, which indicates that our model may be flawed. Let’s overlay the model on a plot of the data.\n\n\nCode\n# Predict the fitted values from the mixed-effects model\nsleepstudy$fitted_reaction &lt;- predict(reaction_model)\n\n# Create a scatterplot of fitted reaction times against Days\nggplot(sleepstudy) +\n  aes(x = Days, y = fitted_reaction, color = Subject) +\n   # geom_point() +\n   geom_line() +\n   labs(title = \"Reaction time vs. days by subject\",\n        x = \"Days of sleep deprivation\",\n        y = \"Reaction time (ms)\") +\n  geom_point(data=sleepstudy, mapping=aes(x=Days, y=Reaction, color=Subject))\n\n\n\n\n\nThis gives a nice ilustration of the random intercepts. It also shows us that the residuals are apparently less variable when there are fewer days of sleep deprivation, and get more variable later. We can also see that the colors of the most extreme points seems consistent on both the lower and upper limits of the plot. Looking at those most extreme points, it looks like the orange points at the bottom of the plot are in a flatter slope than the blue dots at the top of the plot. Perhaps a random slope can help model the increasing spread of the responses.\n\n\n6.4.3 Random slope model\nThe most common kind of random effect is a random intercept. That means the effect of a grouping level is a consistent adjustment (increase or decrease) to the response. But random effects can be more complicated, such random slopes - where the effect of a continuous variable changes according to the grouping variable.\nHere’s what that means for the sleep study data: the random intercept model assumes that each subject’s reaction time was has somewhat quicker or slower than average, but everyone’s reaction time changes by the same amount each day. This is why all the lines in the last plot are parallel to each other. With random slopes, each subject’s reaction time changes by a personally unique amount each day. Meanwhile, the average change in reaction time per day is the fixed slope of Days.\n\nrandom_slope_model =\n  lmer(Reaction ~ Days + (1 + Days|Subject), data=sleepstudy)\n\nLooking at the plot of random effects, we see that the people with the quickest reactions also were less affected by sleep deprivation (lowest lines have the flattest slopes), and the people with the slowest reactions also were most affected by sleep deprivation (highest lines have the steepest slopes.)\n\n\nCode\n# Predict the fitted values from the mixed-effects model\nsleepstudy$random_slope_fitted &lt;- predict(random_slope_model)\n\n# Create a scatterplot of fitted reaction times against Days\nggplot(sleepstudy) +\n  aes(x = Days, y = random_slope_fitted, color = Subject) +\n   geom_line() +\n   labs(title = \"Reaction time vs. days by subject\",\n        x = \"Days of sleep deprivation\",\n        y = \"Reaction time (ms)\") +\n  geom_point(data=sleepstudy, mapping=aes(x=Days, y=Reaction, color=Subject))\n\n\n\n\n\n\n\n6.4.4 Interpretation\nFirst off, let’s look at the diagnostic plots of the random slope model:\n\n\nCode\n# make the residual vs fitted plot for the model:\nfit_v_resid_rand_slope = plot(random_slope_model)\n\n# make the QQ plot:\nqq_rand_slope = lattice::qqmath(random_slope_model)\n\n# draw the plots\ncowplot::plot_grid(fit_v_resid_rand_slope, qq_rand_slope, ncol=2)\n\n\n\n\n\nWe’ve made progress toward improving the shape of the residual distribution. Most of what look like problems in these figures are due to two subjects who had wildly fluctuating reaction times. You could make an argument to remove those subjects but I don’t think we should be throwing out data that isn’t contaminated so I will choose to keep the model as is. Now check the model summary.\n\nsummary(random_slope_model)\n\nLinear mixed model fit by REML ['lmerMod']\nFormula: Reaction ~ Days + (1 + Days | Subject)\n   Data: sleepstudy\n\nREML criterion at convergence: 1743.6\n\nScaled residuals: \n    Min      1Q  Median      3Q     Max \n-3.9536 -0.4634  0.0231  0.4634  5.1793 \n\nRandom effects:\n Groups   Name        Variance Std.Dev. Corr\n Subject  (Intercept) 612.10   24.741       \n          Days         35.07    5.922   0.07\n Residual             654.94   25.592       \nNumber of obs: 180, groups:  Subject, 18\n\nFixed effects:\n            Estimate Std. Error t value\n(Intercept)  251.405      6.825  36.838\nDays          10.467      1.546   6.771\n\nCorrelation of Fixed Effects:\n     (Intr)\nDays -0.138\n\n\nThere are some changes to the random effects part of the summary because there is now a new row under Group:Subject and Name:Days. This row reports the differences in slopes between the subjects. It also has a new column, Corr, which has only one value. It reports the correlation between different random effects applied to the same grouping feature, which in this case are the random intercept and random slope for each subject. The (slightly) positive correlation between the random slope and random intercept confirms that the model sees people with fast reactions as also being less affected by sleep deprivation, and vice versa."
  }
]